{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate the Normalised key point values in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hand Landmark Detection model\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)  # 0 for default camera\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    # Process the frame with MediaPipe Hand Landmark Detection\n",
    "    results = mp_hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # If hand landmarks are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Get the first detected hand\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "        # Draw landmarks and annotate with normalized values\n",
    "        for id, landmark in enumerate(hand_landmarks.landmark):\n",
    "            x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.putText(frame, f\"{landmark.x:.2f}, {landmark.y:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"Hand Landmarks\", frame)\n",
    "\n",
    "    # Check for the 'q' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hand Landmark Detection model\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)  # 0 for default camera\n",
    "\n",
    "# Create directory to save captured photos\n",
    "os.makedirs(\"photo_captured\", exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Process the frame with MediaPipe Hand Landmark Detection\n",
    "    results = mp_hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Convert the image color back so it can be displayed with OpenCV\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Get the first detected hand\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "        # Get the bounding box coordinates\n",
    "        x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "        y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "        x_min = int(min(x_coords) * frame.shape[1])\n",
    "        x_max = int(max(x_coords) * frame.shape[1])\n",
    "        y_min = int(min(y_coords) * frame.shape[0])\n",
    "        y_max = int(max(y_coords) * frame.shape[0])\n",
    "\n",
    "        # Draw the bounding box with different color\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 255), 2)\n",
    "\n",
    "        # Draw scale on the bounding box\n",
    "        for i in range(11):\n",
    "            x_pos = x_min + i * (x_max - x_min) // 10\n",
    "            y_pos = y_min + i * (y_max - y_min) // 10\n",
    "            cv2.line(image, (x_pos, y_min), (x_pos, y_min - 10), (0, 255, 255), 1)\n",
    "            cv2.line(image, (x_min, y_pos), (x_min - 10, y_pos), (0, 255, 255), 1)\n",
    "            # Mark the values on the axis lines\n",
    "            cv2.putText(image, f'{i/10:.1f}', (x_pos, y_min - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "            cv2.putText(image, f'{i/10:.1f}', (x_min - 25, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "\n",
    "        # Draw landmarks and annotate with normalized values\n",
    "        for id, landmark in enumerate(hand_landmarks.landmark):\n",
    "            x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.putText(image, f\"{landmark.x:.2f}, {landmark.y:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"Hand Landmarks\", image)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        # Save the current frame with annotations\n",
    "        filename = f\"photo_captured/frame_{cv2.getTickCount()}.png\"\n",
    "        cv2.imwrite(filename, image)\n",
    "        print(f\"Captured and saved {filename}\")\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Corrected\n",
    "\n",
    "# press \"S\" to capture and save the frame at any time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe hands and drawing modules\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set up MediaPipe Hands with default parameters\n",
    "with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image and detect hands\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Convert the image color back so it can be displayed with OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the bounding box coordinates\n",
    "                x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "                y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "                x_min = int(min(x_coords) * frame.shape[1])\n",
    "                x_max = int(max(x_coords) * frame.shape[1])\n",
    "                y_min = int(min(y_coords) * frame.shape[0])\n",
    "                y_max = int(max(y_coords) * frame.shape[0])\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "                # Draw scale on the bounding box\n",
    "                for i in range(11):\n",
    "                    x_pos = x_min + i * (x_max - x_min) // 10\n",
    "                    y_pos = y_min + i * (y_max - y_min) // 10\n",
    "                    cv2.line(image, (x_pos, y_min), (x_pos, y_min - 10), (0, 255, 0), 1)\n",
    "                    cv2.line(image, (x_min, y_pos), (x_min - 10, y_pos), (0, 255, 0), 1)\n",
    "\n",
    "                # Optionally, draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Display normalized keypoints\n",
    "                for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                    x_disp = int(x * frame.shape[1])\n",
    "                    y_disp = int(y * frame.shape[0])\n",
    "                    cv2.putText(image, f'{idx}: ({x:.2f}, {y:.2f})', (x_disp, y_disp), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe hands and drawing modules\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create directory to save captured photos\n",
    "os.makedirs(\"photo_captured\", exist_ok=True)\n",
    "\n",
    "# Set up MediaPipe Hands with default parameters\n",
    "with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image and detect hands\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Convert the image color back so it can be displayed with OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the bounding box coordinates\n",
    "                x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "                y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "                x_min = int(min(x_coords) * frame.shape[1])\n",
    "                x_max = int(max(x_coords) * frame.shape[1])\n",
    "                y_min = int(min(y_coords) * frame.shape[0])\n",
    "                y_max = int(max(y_coords) * frame.shape[0])\n",
    "\n",
    "                # Draw the bounding box with different color\n",
    "                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 255), 2)\n",
    "\n",
    "                # Draw scale on the bounding box\n",
    "                for i in range(11):\n",
    "                    x_pos = x_min + i * (x_max - x_min) // 10\n",
    "                    y_pos = y_min + i * (y_max - y_min) // 10\n",
    "                    cv2.line(image, (x_pos, y_min), (x_pos, y_min - 10), (0, 255, 255), 1)\n",
    "                    cv2.line(image, (x_min, y_pos), (x_min - 10, y_pos), (0, 255, 255), 1)\n",
    "                    # Mark the values on the axis lines\n",
    "                    cv2.putText(image, f'{i/10:.1f}', (x_pos, y_min - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "                    cv2.putText(image, f'{i/10:.1f}', (x_min - 25, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "\n",
    "                # Optionally, draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Display normalized keypoints with different color\n",
    "                for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                    x_disp = int(x * frame.shape[1])\n",
    "                    y_disp = int(y * frame.shape[0])\n",
    "                    cv2.putText(image, f'{idx}: ({x:.2f}, {y:.2f})', (x_disp, y_disp), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        key = cv2.waitKey(5) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            # Save the current frame\n",
    "            filename = f\"photo_captured/frame_{cv2.getTickCount()}.png\"\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Captured and saved {filename}\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe hands and drawing modules\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create directory to save captured photos\n",
    "os.makedirs(\"photo_captured\", exist_ok=True)\n",
    "\n",
    "# Set up MediaPipe Hands with default parameters\n",
    "with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image and detect hands\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Convert the image color back so it can be displayed with OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the bounding box coordinates\n",
    "                x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "                y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "                x_min = min(x_coords)\n",
    "                x_max = max(x_coords)\n",
    "                y_min = min(y_coords)\n",
    "                y_max = max(y_coords)\n",
    "\n",
    "                # Draw the bounding box with different color\n",
    "                cv2.rectangle(image, (int(x_min * frame.shape[1]), int(y_min * frame.shape[0])), \n",
    "                     (int(x_max * frame.shape[1]), int(y_max * frame.shape[0])), (0, 255, 255), 2)\n",
    "\n",
    "                # Draw scale on the bounding box\n",
    "                for i in range(11):\n",
    "                    x_pos = x_min + i * (x_max - x_min) / 10\n",
    "                    y_pos = y_min + i * (y_max - y_min) / 10\n",
    "                    cv2.line(image, (int(x_pos * frame.shape[1]), int(y_min * frame.shape[0])), \n",
    "                                    (int(x_pos * frame.shape[1]), int((y_min - 0.1) * frame.shape[0])), (0, 255, 255), 1)\n",
    "                    cv2.line(image, (int(x_min * frame.shape[1]), int(y_pos * frame.shape[0])), \n",
    "                                    (int((x_min - 0.1) * frame.shape[1]), int(y_pos * frame.shape[0])), (0, 255, 255), 1)\n",
    "                    # Mark the values on the axis lines\n",
    "                    cv2.putText(image, f'{i/10:.1f}', (int(x_pos * frame.shape[1]), int((y_min - 0.15) * frame.shape[0])), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "                    cv2.putText(image, f'{i/10:.1f}', (int((x_min - 0.25) * frame.shape[1]), int(y_pos * frame.shape[0])), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "\n",
    "                # Optionally, draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Display normalized keypoints with different color\n",
    "                for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    x_disp = int(landmark.x * frame.shape[1])\n",
    "                    y_disp = int(landmark.y * frame.shape[0])\n",
    "                    cv2.putText(image, f'{idx}: ({landmark.x:.2f}, {landmark.y:.2f})', (x_disp, y_disp), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        key = cv2.waitKey(5) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            # Save the current frame with annotations\n",
    "            filename = f\"photo_captured/frame_{cv2.getTickCount()}.png\"\n",
    "            cv2.imwrite(filename, image)  # Save the image with annotations\n",
    "            print(f\"Captured and saved {filename}\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured and saved photo_captured/skeleton_46884224307700.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe hands and drawing modules\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create directory to save captured photos\n",
    "os.makedirs(\"photo_captured\", exist_ok=True)\n",
    "\n",
    "# Set up MediaPipe Hands with default parameters\n",
    "with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image and detect hands\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Convert the image color back so it can be displayed with OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the bounding box coordinates\n",
    "                x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "                y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "                x_min = int(min(x_coords) * frame.shape[1])\n",
    "                x_max = int(max(x_coords) * frame.shape[1])\n",
    "                y_min = int(min(y_coords) * frame.shape[0])\n",
    "                y_max = int(max(y_coords) * frame.shape[0])\n",
    "\n",
    "                # Draw the bounding box with different color\n",
    "                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 255), 2)\n",
    "\n",
    "                # Draw scale on the bounding box\n",
    "                for i in range(11):\n",
    "                    x_pos = x_min + i * (x_max - x_min) // 10\n",
    "                    y_pos = y_min + i * (y_max - y_min) // 10\n",
    "                    cv2.line(image, (x_pos, y_min), (x_pos, y_min - 10), (0, 255, 255), 1)\n",
    "                    cv2.line(image, (x_min, y_pos), (x_min - 10, y_pos), (0, 255, 255), 1)\n",
    "                    # Mark the values on the axis lines\n",
    "                    cv2.putText(image, f'{i/10:.1f}', (x_pos, y_min - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "                    cv2.putText(image, f'{i/10:.1f}', (x_min - 25, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "\n",
    "                # Optionally, draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Display normalized keypoints with different color\n",
    "                for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                    x_disp = int((x - min(x_coords)) / (max(x_coords) - min(x_coords)) * (x_max - x_min) + x_min)\n",
    "                    y_disp = int((y - min(y_coords)) / (max(y_coords) - min(y_coords)) * (y_max - y_min) + y_min)\n",
    "                    cv2.putText(image, f'{idx}: ({x:.2f}, {y:.2f})', (x_disp, y_disp), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        key = cv2.waitKey(5) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            # Save the current frame with annotations\n",
    "            filename = f\"photo_captured/frame_{cv2.getTickCount()}.png\"\n",
    "            cv2.imwrite(filename, image)  # Save the image with annotations\n",
    "            print(f\"Captured and saved {filename}\")\n",
    "        elif key == ord('s'):\n",
    "            # Create a white background image\n",
    "            white_image = 255 * np.ones_like(frame)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    # Get the bounding box coordinates\n",
    "                    x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "                    y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "                    x_min = int(min(x_coords) * frame.shape[1])\n",
    "                    x_max = int(max(x_coords) * frame.shape[1])\n",
    "                    y_min = int(min(y_coords) * frame.shape[0])\n",
    "                    y_max = int(max(y_coords) * frame.shape[0])\n",
    "\n",
    "                    # Draw the bounding box with different color\n",
    "                    cv2.rectangle(white_image, (x_min, y_min), (x_max, y_max), (0, 255, 255), 2)\n",
    "\n",
    "                    # Draw scale on the bounding box\n",
    "                    for i in range(11):\n",
    "                        x_pos = x_min + i * (x_max - x_min) // 10\n",
    "                        y_pos = y_min + i * (y_max - y_min) // 10\n",
    "                        cv2.line(white_image, (x_pos, y_min), (x_pos, y_min - 10), (0, 255, 255), 1)\n",
    "                        cv2.line(white_image, (x_min, y_pos), (x_min - 10, y_pos), (0, 255, 255), 1)\n",
    "                        # Mark the values on the axis lines\n",
    "                        cv2.putText(white_image, f'{i/10:.1f}', (x_pos, y_min - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "                        cv2.putText(white_image, f'{i/10:.1f}', (x_min - 25, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)\n",
    "\n",
    "                    # Draw hand landmarks on white background\n",
    "                    mp_drawing.draw_landmarks(white_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Display normalized keypoints with different color\n",
    "                    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                        x = landmark.x\n",
    "                        y = landmark.y\n",
    "                        x_disp = int((x - min(x_coords)) / (max(x_coords) - min(x_coords)) * (x_max - x_min) + x_min)\n",
    "                        y_disp = int((y - min(y_coords)) / (max(y_coords) - min(y_coords)) * (y_max - y_min) + y_min)\n",
    "                        cv2.putText(white_image, f'{idx}: ({x:.2f}, {y:.2f})', (x_disp, y_disp), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            # Save the skeleton image\n",
    "            skeleton_filename = f\"photo_captured/skeleton_{cv2.getTickCount()}.png\"\n",
    "            cv2.imwrite(skeleton_filename, white_image)  # Save the skeleton image\n",
    "            print(f\"Captured and saved {skeleton_filename}\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalhand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
